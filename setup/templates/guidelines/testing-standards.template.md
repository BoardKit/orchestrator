# Testing Standards

<!-- AUTO-GENERATED - Generated by setup wizard on {{TIMESTAMP}} -->

**Last Updated:** {{TIMESTAMP}}

---

## Overview

This document defines testing standards and best practices for the **{{ORG_NAME}}** system.

**Tech Stack:** {{COMBINED_TECH_STACK}}

---

## Testing Philosophy

**Core Principles:**
1. Test behavior, not implementation
2. Write tests that provide confidence
3. Keep tests fast and reliable
4. Test at the appropriate level
5. Maintain tests as carefully as production code

---

{{TESTING_BY_TECH_STACK}}

---

## Test Organization

{{TEST_ORGANIZATION_PATTERNS}}

**General Structure:**
```
tests/
├── unit/           # Fast, isolated tests
├── integration/    # Tests with dependencies
└── e2e/            # End-to-end user flows
```

---

## Naming Conventions

{{TEST_NAMING_PATTERNS}}

**General Patterns:**
- Describe what is being tested
- Include the scenario/condition
- State the expected outcome
- Example: `test_user_login_with_invalid_credentials_returns_401`

---

## Mock Patterns

{{MOCKING_PATTERNS}}

**When to Mock:**
- ✅ External APIs and services
- ✅ Databases (for unit tests)
- ✅ Time-dependent behavior
- ✅ File system operations
- ❌ Internal business logic (test it directly)
- ❌ Simple utility functions

---

## Test Data

{{TEST_DATA_PATTERNS}}

**Best Practices:**
- Use factories/fixtures for consistent test data
- Clean up after tests (especially integration tests)
- Don't rely on order of test execution
- Use realistic data that represents production scenarios

---

## Coverage Standards

{{COVERAGE_STANDARDS}}

**General Guidelines:**
- Aim for 80%+ code coverage
- 100% coverage of critical paths
- Test all error conditions
- Don't chase 100% coverage at the expense of test quality

---

## Testing Strategies by Layer

{{TESTING_BY_LAYER}}

---

## Common Testing Scenarios

{{COMMON_TEST_SCENARIOS}}

---

## Continuous Integration

{{CI_TESTING_PATTERNS}}

**CI Requirements:**
- All tests must pass before merge
- Run tests on every commit
- Fast feedback loop (< 10 minutes)
- Parallel test execution when possible

---

## Best Practices

{{TESTING_BEST_PRACTICES}}

**Universal Best Practices:**
- ✅ Write tests before or alongside code
- ✅ Keep tests simple and focused
- ✅ Use descriptive test names
- ✅ Test edge cases and error conditions
- ✅ Make tests independent
- ✅ Run tests frequently during development
- ❌ Don't write flaky tests
- ❌ Don't skip failing tests
- ❌ Don't test implementation details
- ❌ Don't share state between tests

---

## Examples

{{TESTING_EXAMPLES}}

---

## Debugging Failed Tests

{{TEST_DEBUGGING_PATTERNS}}

**Steps:**
1. Read the error message carefully
2. Check recent code changes
3. Run the test in isolation
4. Add debug logging
5. Check test data and mocks
6. Verify test environment

---

## References

- **Architecture:** See `architectural-principles.md` for system structure
- **Error Handling:** See `error-handling.md` for error testing patterns
- **Skills:** Repo-specific skills provide tech-stack-specific testing guidance

---

## Notes for AI Agents

When writing tests:
1. Check which tech stack and test framework is used
2. Follow patterns defined in this document
3. Write tests at the appropriate level (unit/integration/e2e)
4. Ensure tests are independent and reliable
5. Use meaningful test names and assertions

---

**Generated:** {{TIMESTAMP}}
**Organization:** {{ORG_NAME}}
**Tech Stacks:** {{COMBINED_TECH_STACK}}
